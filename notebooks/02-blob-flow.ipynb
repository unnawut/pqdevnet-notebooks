{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of blob flow through validators, builders, and relays on Ethereum mainnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors as pc\n",
    "\n",
    "from loaders import load_parquet, display_sql\n",
    "\n",
    "MIN_BLOCKS = 10  # Minimum blocks for entity filtering\n",
    "\n",
    "# Margin for Sankey node positioning (prevents cutoff at edges)\n",
    "Y_MARGIN = 0.02\n",
    "\n",
    "target_date = None  # Set via papermill, or auto-detect from manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab3f1e",
   "metadata": {
    "tags": [
     "hide-input",
     "sql-fold"
    ]
   },
   "outputs": [],
   "source": [
    "display_sql(\"blob_flow\", target_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_y_positions(node_weights: list[float], pad: float = 0.02) -> list[float]:\n",
    "    \"\"\"Calculate y positions for nodes based on their weights (flow values).\n",
    "    \n",
    "    Positions nodes so they don't overlap, accounting for their heights which\n",
    "    are proportional to their weights.\n",
    "    \"\"\"\n",
    "    if len(node_weights) == 0:\n",
    "        return []\n",
    "    if len(node_weights) == 1:\n",
    "        return [0.5]\n",
    "    \n",
    "    total_weight = sum(node_weights)\n",
    "    n = len(node_weights)\n",
    "    total_pad = pad * (n - 1)\n",
    "    available_space = 1.0 - 2 * Y_MARGIN - total_pad\n",
    "    \n",
    "    positions = []\n",
    "    current_y = Y_MARGIN\n",
    "    \n",
    "    for i, weight in enumerate(node_weights):\n",
    "        # Node height is proportional to its weight\n",
    "        node_height = (weight / total_weight) * available_space\n",
    "        # Position is at center of node\n",
    "        pos = current_y + node_height / 2\n",
    "        positions.append(pos)\n",
    "        # Move to next position (after this node + padding)\n",
    "        current_y += node_height + pad\n",
    "    \n",
    "    return positions\n",
    "\n",
    "# Sankey domain to leave room at edges\n",
    "SANKEY_DOMAIN = dict(x=[0, 1], y=[0.01, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load blob flow data\n",
    "df_blob_flow = load_parquet(\"blob_flow\", target_date)\n",
    "\n",
    "# Fill missing values\n",
    "df_blob_flow[\"proposer_entity\"] = df_blob_flow[\"proposer_entity\"].fillna(\"Unknown\")\n",
    "df_blob_flow[\"winning_relay\"] = df_blob_flow[\"winning_relay\"].fillna(\"Local/Unknown\")\n",
    "\n",
    "print(f\"Total blocks: {len(df_blob_flow)}\")\n",
    "print(f\"Unique proposer entities: {df_blob_flow['proposer_entity'].nunique()}\")\n",
    "print(f\"Unique relays: {df_blob_flow['winning_relay'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposer Entity -> Blob Count\n",
    "\n",
    "Sankey diagram showing how different staking entities (pools, solo stakers) distribute their blocks across blob counts. Wider flows indicate more blocks. Entities with fewer than 10 blocks are filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Calculate block counts per entity\nentity_block_counts = df_blob_flow.groupby(\"proposer_entity\").size()\n\n# Get entities that meet the threshold\nvalid_entities = entity_block_counts[entity_block_counts >= MIN_BLOCKS].index\n\n# Filter the dataframe\ndf_filtered = df_blob_flow[df_blob_flow[\"proposer_entity\"].isin(valid_entities)]\n\nentity_blob_flow = (\n    df_filtered.groupby([\"proposer_entity\", \"blob_count\"])\n    .size()\n    .reset_index(name=\"block_count\")\n)\n\n# Sort entities by total block count (descending)\nentity_totals = entity_blob_flow.groupby(\"proposer_entity\")[\"block_count\"].sum()\nentities = entity_totals.sort_values(ascending=False).index.tolist()\nblob_counts = sorted(entity_blob_flow[\"blob_count\"].unique(), reverse=True)  # Descending\n\n# Create node labels: entities + blob counts (blob counts sorted descending)\nentity_nodes = [f\"E:{e}\" for e in entities]\nblob_nodes = [f\"{int(bc)} blobs\" for bc in blob_counts]\nall_nodes = entity_nodes + blob_nodes\n\n# Create mapping from name to index\nnode_map = {name: idx for idx, name in enumerate(all_nodes)}\n\n# Calculate node weights (total flow through each node)\nentity_weights = [entity_totals[e] for e in entities]\nblob_totals = entity_blob_flow.groupby(\"blob_count\")[\"block_count\"].sum()\nblob_weights = [blob_totals.get(bc, 0) for bc in blob_counts]\n\nn_entities = len(entity_nodes)\nn_blobs = len(blob_nodes)\n\n# Create color gradient for blob nodes (higher blob count = darker)\nmax_blob = max(blob_counts)\nmin_blob = min(blob_counts)\nblob_colors = [\n    pc.sample_colorscale(\"Amp\", (bc - min_blob) / (max_blob - min_blob) if max_blob > min_blob else 0.5)[0]\n    for bc in blob_counts\n]\nentity_colors = [pc.qualitative.Plotly[i % len(pc.qualitative.Plotly)] for i in range(n_entities)]\n\n# Calculate y positions based on node weights to prevent overlap\nentity_y = calculate_y_positions(entity_weights)\nblob_y = calculate_y_positions(blob_weights)\n\nx_pos = [0.01] * n_entities + [0.99] * n_blobs\ny_pos = entity_y + blob_y\n\nsources = []\ntargets = []\nvalues = []\n\nfor _, row in entity_blob_flow.iterrows():\n    e_node = f\"E:{row['proposer_entity']}\"\n    bc_node = f\"{int(row['blob_count'])} blobs\"\n    if e_node in node_map and bc_node in node_map:\n        sources.append(node_map[e_node])\n        targets.append(node_map[bc_node])\n        values.append(row[\"block_count\"])\n\nfig = go.Figure(\n    data=[\n        go.Sankey(\n            arrangement=\"snap\",\n            domain=SANKEY_DOMAIN,\n            node=dict(\n                pad=15,\n                thickness=20,\n                line=dict(color=\"black\"),\n                label=all_nodes,\n                x=x_pos,\n                y=y_pos,\n                color=entity_colors + blob_colors,\n            ),\n            link=dict(source=sources, target=targets, value=values),\n        )\n    ]\n)\nfig.update_layout(\n    autosize=True,\n    font_size=12,\n    height=6000,\n    margin=dict(t=40, b=40, l=20, r=20)\n)\nfig.show(config={\"responsive\": True})"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relay -> Blob Count\n",
    "\n",
    "Shows which MEV-boost relays are associated with different blob counts. Reveals whether certain relays tend to produce blocks with more or fewer blobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "relay_blob_flow = (\n    df_blob_flow.groupby([\"winning_relay\", \"blob_count\"])\n    .size()\n    .reset_index(name=\"block_count\")\n)\n\n# Sort relays by total block count (descending)\nrelay_totals = relay_blob_flow.groupby(\"winning_relay\")[\"block_count\"].sum()\nrelays = relay_totals.sort_values(ascending=False).index.tolist()\n\nblob_counts = sorted(relay_blob_flow[\"blob_count\"].unique(), reverse=True)  # Descending\n\n# Create node labels: relays + blob counts (blob counts sorted descending)\nrelay_nodes = [f\"R:{r}\" for r in relays]\nblob_nodes = [f\"{int(bc)} blobs\" for bc in blob_counts]\nall_nodes = relay_nodes + blob_nodes\n\n# Create mapping from name to index\nnode_map = {name: idx for idx, name in enumerate(all_nodes)}\n\n# Calculate node weights\nrelay_weights = [relay_totals[r] for r in relays]\nblob_totals = relay_blob_flow.groupby(\"blob_count\")[\"block_count\"].sum()\nblob_weights = [blob_totals.get(bc, 0) for bc in blob_counts]\n\nn_relays = len(relay_nodes)\nn_blobs = len(blob_nodes)\n\n# Create color gradient for blob nodes (higher blob count = darker)\nmax_blob = max(blob_counts)\nmin_blob = min(blob_counts)\nblob_colors = [\n    pc.sample_colorscale(\"Amp\", (bc - min_blob) / (max_blob - min_blob) if max_blob > min_blob else 0.5)[0]\n    for bc in blob_counts\n]\nrelay_colors = [pc.qualitative.Pastel[i % len(pc.qualitative.Pastel)] for i in range(n_relays)]\n\n# Calculate y positions based on node weights\nrelay_y = calculate_y_positions(relay_weights)\nblob_y = calculate_y_positions(blob_weights)\n\nx_pos = [0.01] * n_relays + [0.99] * n_blobs\ny_pos = relay_y + blob_y\n\nsources = []\ntargets = []\nvalues = []\n\nfor _, row in relay_blob_flow.iterrows():\n    r_node = f\"R:{row['winning_relay']}\"\n    bc_node = f\"{int(row['blob_count'])} blobs\"\n    if r_node in node_map and bc_node in node_map:\n        sources.append(node_map[r_node])\n        targets.append(node_map[bc_node])\n        values.append(row[\"block_count\"])\n\nfig = go.Figure(\n    data=[\n        go.Sankey(\n            arrangement=\"snap\",\n            domain=SANKEY_DOMAIN,\n            node=dict(\n                pad=15,\n                thickness=20,\n                line=dict(color=\"black\"),\n                label=all_nodes,\n                x=x_pos,\n                y=y_pos,\n                color=relay_colors + blob_colors,\n            ),\n            link=dict(source=sources, target=targets, value=values),\n        )\n    ]\n)\nfig.update_layout(\n    autosize=True,\n    font_size=12,\n    height=1200,\n    margin=dict(t=40, b=40, l=20, r=20)\n)\nfig.show(config={\"responsive\": True})"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposer Entity -> Relay\n",
    "\n",
    "Maps which staking entities use which relays. Shows the relationship between validators and the MEV-boost relay infrastructure they rely on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Calculate block counts per entity\nentity_block_counts = df_blob_flow.groupby(\"proposer_entity\").size()\nvalid_entities = entity_block_counts[entity_block_counts >= MIN_BLOCKS].index\n\n# Filter the dataframe\ndf_filtered = df_blob_flow[df_blob_flow[\"proposer_entity\"].isin(valid_entities)]\n\nproposer_relay_flow = (\n    df_filtered.groupby([\"proposer_entity\", \"winning_relay\"])\n    .size()\n    .reset_index(name=\"block_count\")\n)\n\n# Sort entities by total block count (descending)\nentity_totals = proposer_relay_flow.groupby(\"proposer_entity\")[\"block_count\"].sum()\nentities = entity_totals.sort_values(ascending=False).index.tolist()\n\n# Sort relays by total block count (descending)\nrelay_totals = proposer_relay_flow.groupby(\"winning_relay\")[\"block_count\"].sum()\nrelays = relay_totals.sort_values(ascending=False).index.tolist()\n\n# Create node labels: entities + relays\nentity_nodes = [f\"E:{e}\" for e in entities]\nrelay_nodes = [f\"R:{r}\" for r in relays]\nall_nodes = entity_nodes + relay_nodes\n\n# Create mapping from name to index\nnode_map = {name: idx for idx, name in enumerate(all_nodes)}\n\n# Calculate node weights\nentity_weights = [entity_totals[e] for e in entities]\nrelay_weights = [relay_totals[r] for r in relays]\n\nn_entities = len(entity_nodes)\nn_relays = len(relay_nodes)\n\nentity_colors = [pc.qualitative.Plotly[i % len(pc.qualitative.Plotly)] for i in range(n_entities)]\nrelay_colors = [pc.qualitative.Pastel[i % len(pc.qualitative.Pastel)] for i in range(n_relays)]\n\n# Calculate y positions based on node weights\nentity_y = calculate_y_positions(entity_weights)\nrelay_y = calculate_y_positions(relay_weights)\n\nx_pos = [0.01] * n_entities + [0.99] * n_relays\ny_pos = entity_y + relay_y\n\nsources = []\ntargets = []\nvalues = []\n\nfor _, row in proposer_relay_flow.iterrows():\n    e_node = f\"E:{row['proposer_entity']}\"\n    r_node = f\"R:{row['winning_relay']}\"\n    if e_node in node_map and r_node in node_map:\n        sources.append(node_map[e_node])\n        targets.append(node_map[r_node])\n        values.append(row[\"block_count\"])\n\nfig = go.Figure(\n    data=[\n        go.Sankey(\n            arrangement=\"snap\",\n            domain=SANKEY_DOMAIN,\n            node=dict(\n                pad=15,\n                thickness=20,\n                line=dict(color=\"black\"),\n                label=all_nodes,\n                x=x_pos,\n                y=y_pos,\n                color=entity_colors + relay_colors,\n            ),\n            link=dict(source=sources, target=targets, value=values),\n        )\n    ]\n)\nfig.update_layout(\n    autosize=True,\n    font_size=12,\n    height=6000,\n    margin=dict(t=40, b=40, l=20, r=20)\n)\nfig.show(config={\"responsive\": True})"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposer Entity -> Relay -> Blob Count\n",
    "\n",
    "Complete three-stage flow: from staking entities through relays to final blob counts. This comprehensive view shows the full pipeline of how blobs flow through the Ethereum block production ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Calculate block counts per entity\nentity_block_counts = df_blob_flow.groupby(\"proposer_entity\").size()\nvalid_entities = entity_block_counts[entity_block_counts >= MIN_BLOCKS].index\n\n# Filter the dataframe\ndf_filtered = df_blob_flow[df_blob_flow[\"proposer_entity\"].isin(valid_entities)]\n\n# Aggregate flows: entity -> relay\nentity_relay_flow = (\n    df_filtered.groupby([\"proposer_entity\", \"winning_relay\"])\n    .size()\n    .reset_index(name=\"block_count\")\n)\n\n# Aggregate flows: relay -> blob_count\nrelay_blob_flow = (\n    df_filtered.groupby([\"winning_relay\", \"blob_count\"])\n    .size()\n    .reset_index(name=\"block_count\")\n)\n\n# Sort entities by total block count (descending)\nentity_totals = entity_relay_flow.groupby(\"proposer_entity\")[\"block_count\"].sum()\nentities = entity_totals.sort_values(ascending=False).index.tolist()\n\n# Sort relays by total block count (descending)\nrelay_totals = relay_blob_flow.groupby(\"winning_relay\")[\"block_count\"].sum()\nrelays = relay_totals.sort_values(ascending=False).index.tolist()\n\nblob_counts = sorted(df_filtered[\"blob_count\"].unique(), reverse=True)  # Descending\n\n# Create node labels: entities + relays + blob counts\nentity_nodes = [f\"E:{e}\" for e in entities]\nrelay_nodes = [f\"R:{r}\" for r in relays]\nblob_nodes = [f\"{int(bc)} blobs\" for bc in blob_counts]\nall_nodes = entity_nodes + relay_nodes + blob_nodes\n\n# Create mapping from name to index\nnode_map = {name: idx for idx, name in enumerate(all_nodes)}\n\nn_entities = len(entity_nodes)\nn_relays = len(relay_nodes)\nn_blobs = len(blob_nodes)\n\n# Calculate node weights\nentity_weights = [entity_totals[e] for e in entities]\nrelay_weights = [relay_totals[r] for r in relays]\nblob_totals = relay_blob_flow.groupby(\"blob_count\")[\"block_count\"].sum()\nblob_weights = [blob_totals.get(bc, 0) for bc in blob_counts]\n\nentity_colors = [pc.qualitative.Plotly[i % len(pc.qualitative.Plotly)] for i in range(n_entities)]\nrelay_colors = [pc.qualitative.Pastel[i % len(pc.qualitative.Pastel)] for i in range(n_relays)]\nmax_blob = max(blob_counts)\nmin_blob = min(blob_counts)\nblob_colors = [\n    pc.sample_colorscale(\"Amp\", (bc - min_blob) / (max_blob - min_blob) if max_blob > min_blob else 0.5)[0]\n    for bc in blob_counts\n]\n\n# Calculate y positions based on node weights\nentity_y = calculate_y_positions(entity_weights)\nrelay_y = calculate_y_positions(relay_weights)\nblob_y = calculate_y_positions(blob_weights)\n\nx_pos = [0.01] * n_entities + [0.5] * n_relays + [0.99] * n_blobs\ny_pos = entity_y + relay_y + blob_y\n\nsources = []\ntargets = []\nvalues = []\n\n# Entity -> Relay links\nfor _, row in entity_relay_flow.iterrows():\n    e_node = f\"E:{row['proposer_entity']}\"\n    r_node = f\"R:{row['winning_relay']}\"\n    if e_node in node_map and r_node in node_map:\n        sources.append(node_map[e_node])\n        targets.append(node_map[r_node])\n        values.append(row[\"block_count\"])\n\n# Relay -> Blob count links\nfor _, row in relay_blob_flow.iterrows():\n    r_node = f\"R:{row['winning_relay']}\"\n    bc_node = f\"{int(row['blob_count'])} blobs\"\n    if r_node in node_map and bc_node in node_map:\n        sources.append(node_map[r_node])\n        targets.append(node_map[bc_node])\n        values.append(row[\"block_count\"])\n\nfig = go.Figure(\n    data=[\n        go.Sankey(\n            arrangement=\"snap\",\n            domain=SANKEY_DOMAIN,\n            node=dict(\n                pad=15,\n                thickness=30,\n                line=dict(color=\"black\"),\n                label=all_nodes,\n                x=x_pos,\n                y=y_pos,\n                color=entity_colors + relay_colors + blob_colors,\n            ),\n            link=dict(source=sources, target=targets, value=values),\n        )\n    ]\n)\nfig.update_layout(\n    autosize=True,\n    title=dict(\n        text=f\"Blob flow: Proposer Entity -> Relay -> Blob Count (min {MIN_BLOCKS} blocks)\",\n        font=dict(size=14),\n    ),\n    font_size=12,\n    height=6000,\n    margin=dict(t=50, b=40, l=20, r=20)\n)\nfig.show(config={\"responsive\": True})"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}